{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 - object removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def imshow(img):\n",
    "    img = img.clip(0, 255).astype(\"uint8\")\n",
    "    if img.ndim == 3:\n",
    "        if img.shape[2] == 4:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGRA2RGBA)\n",
    "        else:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    display(PIL.Image.fromarray(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('DJI_20231031123737_0028_W.JPG')\n",
    "img2 = cv2.imread('DJI_20231031123813_0040_W.JPG')\n",
    "img3 = cv2.imread('DJI_20231031123834_0047_W.JPG')\n",
    "img4 = cv2.imread('fnal1.jpg')\n",
    "img5 = cv2.imread('fnal2.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixel average and median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_img = np.stack((img1, img2, img3))\n",
    "average_img = np.average(stacked_img, axis=0)\n",
    "median_img = np.median(stacked_img, axis=0)\n",
    "print(\"average:\")\n",
    "imshow(average_img)\n",
    "print(\"median:\")\n",
    "imshow(median_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open(img):\n",
    "    return cv2.dilate(cv2.erode(img, np.ones((4,4))), np.ones((4,4)))\n",
    "\n",
    "def close(img):\n",
    "    return cv2.erode(cv2.dilate(img, np.ones((3,3))), np.ones((3,3)))\n",
    "\n",
    "def proper_open(img):\n",
    "    to_compare = close(open(close(img)))\n",
    "    stack = np.stack((img, to_compare))\n",
    "    return np.min(stack, axis=0)\n",
    "\n",
    "def proper_close(img):\n",
    "    to_compare = open(close(open(img)))\n",
    "    stack = np.stack((img, to_compare))\n",
    "    return np.max(stack, axis=0)\n",
    "\n",
    "def automedian_filter(img):\n",
    "    to_compare = proper_open(img)\n",
    "    stack = np.stack((img, to_compare))\n",
    "    return np.max(stack, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_grayscale = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "img2_grayscale = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "img3_grayscale = cv2.cvtColor(img3, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "img1_sobel = np.abs(cv2.Sobel(img1_grayscale, cv2.CV_64F, 1, 0, ksize=3))\n",
    "img2_sobel = np.abs(cv2.Sobel(img2_grayscale, cv2.CV_64F, 1, 0, ksize=3))\n",
    "img3_sobel = np.abs(cv2.Sobel(img3_grayscale, cv2.CV_64F, 1, 0, ksize=3))\n",
    "\n",
    "stacked_sobel = np.stack((img1_sobel, img2_sobel, img3_sobel))\n",
    "sobel_min = np.min(stacked_sobel, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sobel_min[sobel_min < 2] = 0\n",
    "\n",
    "reduced = img1_sobel - 5 * sobel_min\n",
    "open_result1 = (open(reduced))\n",
    "binarized1 = (open_result1 > 0).astype(np.uint8) * 255\n",
    "\n",
    "\n",
    "reduced = img2_sobel - 5 * sobel_min\n",
    "open_result2 = (open(reduced))\n",
    "binarized2 = (open_result2 > 0).astype(np.uint8) * 255\n",
    "\n",
    "reduced = img3_sobel - 5 * sobel_min\n",
    "open_result3 = (open(reduced))\n",
    "binarized3 = (open_result3 > 0).astype(np.uint8) * 255\n",
    "\n",
    "for i in range(3):\n",
    "    binarized1 = cv2.dilate(binarized1, np.ones((20,20)))\n",
    "    binarized2 = cv2.dilate(binarized2, np.ones((20,20)))\n",
    "    binarized3 = cv2.dilate(binarized3, np.ones((20,20)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images=[]\n",
    "for img, mask in zip([img1,img2,img3], [binarized1,binarized2, binarized3]):\n",
    "    images.append(cv2.inpaint(img, mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA))\n",
    "stacked_img=np.stack(images)\n",
    "for x in images:\n",
    "    imshow(x)\n",
    "inpainted_image = np.median(stacked_img, axis=0)\n",
    "imshow(inpainted_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Automedian(img, s):\n",
    "  return np.maximum(cv2.morphologyEx(cv2.morphologyEx(cv2.morphologyEx(img.copy(), cv2.MORPH_OPEN, s), cv2.MORPH_CLOSE, s), cv2.MORPH_OPEN, s),np.minimum(cv2.morphologyEx(cv2.morphologyEx(cv2.morphologyEx(img.copy(), cv2.MORPH_CLOSE, s), cv2.MORPH_OPEN, s), cv2.MORPH_CLOSE, s), img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open(img,s):\n",
    "    return cv2.dilate(cv2.erode(img, s), s)\n",
    "\n",
    "def close(img,s):\n",
    "    return cv2.erode(cv2.dilate(img, s), s)\n",
    "\n",
    "def proper_open(img,s):\n",
    "    to_compare = close(open(close(img,s),s),s)\n",
    "    stack = np.stack((img, to_compare))\n",
    "    return np.min(stack, axis=0)\n",
    "\n",
    "def proper_close(img,s):\n",
    "    to_compare = open(close(open(img,s),s),s)\n",
    "    stack = np.stack((img, to_compare))\n",
    "    return np.max(stack, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "    gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    gray3 = cv2.cvtColor(img3, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    stacked_img = np.stack((img1, img2, img3))\n",
    "\n",
    "    median_img = np.median(stacked_img, axis=0).astype(np.uint8)\n",
    "    gray4=cv2.cvtColor(img4, cv2.COLOR_BGR2GRAY)\n",
    "    # Compute absolute differences between consecutive frames\n",
    "    diff1 = cv2.absdiff(gray1, gray4)\n",
    "    diff2 = cv2.absdiff(gray2, gray4)\n",
    "    diff3 = cv2.absdiff(gray3, gray4)\n",
    "    # Threshold the differences to get a binary mask\n",
    "    _, thresh1 = cv2.threshold(diff1, 70, 255, cv2.THRESH_BINARY)\n",
    "    _, thresh2 = cv2.threshold(diff2, 70, 255, cv2.THRESH_BINARY)\n",
    "    _, thresh3 = cv2.threshold(diff3, 70, 255, cv2.THRESH_BINARY)\n",
    "    s=np.ones((5,5))\n",
    "    \n",
    "    \n",
    " \n",
    "\n",
    "    # Combine the binary masks\n",
    "    combined_mask = cv2.bitwise_or(cv2.bitwise_or(thresh1, thresh2), thresh3)\n",
    "        # Apply morphological operations to improve the mask\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "\n",
    "    combined_mask = Automedian(combined_mask, kernel)\n",
    "\n",
    "    combined_mask=proper_open(combined_mask, np.ones((3,3)))\n",
    "    combined_mask=Automedian(combined_mask, np.ones((21,21)))\n",
    "    \n",
    "    imshow(combined_mask)\n",
    "   # Inpainting to fill in the gaps\n",
    "    inpainted_image1 = cv2.inpaint(median_img.astype(np.uint8), combined_mask, inpaintRadius=31, flags=cv2.INPAINT_TELEA)\n",
    "\n",
    "\n",
    "    img=inpainted_image1\n",
    "    imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((10,10))\n",
    "imshow(thresh1)\n",
    "imshow(thresh2)\n",
    "imshow(thresh3)\n",
    "\n",
    "filled_images = []\n",
    "filled_images2 = []\n",
    "\n",
    "for img_ in [thresh1, thresh2, thresh3]:\n",
    "    img_t = close(img_, kernel)\n",
    "    contours, _ = cv2.findContours(img_t, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "    filled_image = np.zeros_like(img_t)\n",
    "\n",
    "    # Fill concave parts in the contours\n",
    "    for contour in contours:\n",
    "        cv2.drawContours(filled_image, [contour], 0, 255, -1)\n",
    "\n",
    "    imshow(filled_image)\n",
    "    filled_images.append(filled_image)\n",
    "    filled_images2.append(filled_image)\n",
    "\n",
    "for i1, im1 in enumerate(filled_images):\n",
    "    for i2, im2 in enumerate(filled_images2):\n",
    "        if i1 != i2:\n",
    "            pass\n",
    "            #im1[im2.astype(np.bool_)] = 0\n",
    "\n",
    "\n",
    "for im in filled_images:\n",
    "    pass\n",
    "    imshow(im)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_images = list()\n",
    "filtered_images2 = list()\n",
    "\n",
    "for image in filled_images:\n",
    "\n",
    "    # Apply connected component analysis\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(image, connectivity=8)\n",
    "\n",
    "    # Set a threshold for region size\n",
    "    threshold_size = 100  # Adjust this threshold as needed\n",
    "\n",
    "    # Iterate through the regions and filter based on size threshold\n",
    "    filtered_regions = []\n",
    "    for i in range(1, num_labels):  # Start from 1 to skip background (label 0)\n",
    "        region_size = stats[i, cv2.CC_STAT_AREA]\n",
    "        if region_size > threshold_size:\n",
    "            filtered_regions.append(labels == i)\n",
    "\n",
    "    # Visualize the filtered regions\n",
    "    filtered_image = np.zeros_like(image)\n",
    "    for region in filtered_regions:\n",
    "        filtered_image |= region.astype(np.uint8) * 255\n",
    "\n",
    "\n",
    "    # Find extreme points for each filtered region\n",
    "    extreme_points_list = []\n",
    "    for region in filtered_regions:\n",
    "        contours, _ = cv2.findContours(region.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if contours:\n",
    "            contour = contours[0]\n",
    "            extreme_points = np.squeeze(contour, axis=1)\n",
    "            min_x = np.min(extreme_points[:, 0])\n",
    "            min_y = np.min(extreme_points[:, 1])\n",
    "            max_x = np.max(extreme_points[:, 0])\n",
    "            max_y = np.max(extreme_points[:, 1])\n",
    "\n",
    "            filtered_image[min_y:max_y, min_x:max_x] = 255\n",
    "\n",
    "    # Display the resulting image\n",
    "    filtered_images.append(filtered_image)\n",
    "    filtered_images2.append(filtered_image)\n",
    "\n",
    "mask1 = filtered_images[0].astype(np.bool_)\n",
    "mask2 = filtered_images[1].astype(np.bool_)\n",
    "mask3 = filtered_images[2].astype(np.bool_)\n",
    "\n",
    "    \n",
    "mask12 = mask1 & mask2\n",
    "mask13 = mask1 & mask3\n",
    "mask23 = mask2 & mask3\n",
    "\n",
    "for i1, im1 in enumerate(filtered_images):\n",
    "    for i2, im2 in enumerate([mask23, mask13, mask12]):\n",
    "        if i1 != i2:\n",
    "            pass\n",
    "            im1[im2.astype(np.bool_)] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, binarized in zip([img1, img2, img3], filled_images):\n",
    "    stack = np.stack((img, np.repeat(binarized[:,: ,np.newaxis], 3, axis=2)))\n",
    "\n",
    "    imshow(np.average(stack, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    img1_modified = img1.copy()\n",
    "    img2_modified = img2.copy()\n",
    "    img3_modified = img3.copy()\n",
    "\n",
    "    img12_modified = np.stack((img1, img2))\n",
    "    img13_modified = np.stack((img1, img3))\n",
    "    img23_modified = np.stack((img2, img3))\n",
    "    img12_modified = np.median(img12_modified, axis=0)\n",
    "    img13_modified = np.median(img13_modified, axis=0)\n",
    "    img23_modified = np.median(img23_modified, axis=0)\n",
    "\n",
    "    img123_modified = np.stack((img1, img2, img3))\n",
    "    img123_modified = np.median(img123_modified, axis=0)\n",
    "\n",
    "    mask1 = filled_images[0].astype(np.bool_)\n",
    "    mask2 = filled_images[1].astype(np.bool_)\n",
    "    mask3 = filled_images[2].astype(np.bool_)\n",
    "\n",
    "    \n",
    "    mask12 = mask1 & mask2\n",
    "    mask13 = mask1 & mask3\n",
    "    mask23 = mask2 & mask3\n",
    "    \n",
    "    mask123 = mask12 & mask3\n",
    "\n",
    "    img1_modified[mask1 | ~mask2 | ~mask3] = 0\n",
    "    img2_modified[mask2 | ~mask1 | ~mask3] = 0\n",
    "    img3_modified[mask3 | ~mask1 | ~mask2] = 0\n",
    "    img12_modified[mask1 | mask2 | ~mask3] = 0\n",
    "    img13_modified[mask1 | ~mask2 | mask3] = 0\n",
    "    img23_modified[~mask1 | mask2 | mask3] = 0\n",
    "\n",
    "    img123_modified[(mask1 | mask2 | mask3) & ~mask123] = 0\n",
    "\n",
    "    final = np.stack((img1_modified, img2_modified, img3_modified, img12_modified, img13_modified, img23_modified, img123_modified))\n",
    "    final = np.sum(final, axis=0)\n",
    "    imshow(img12_modified)\n",
    "    imshow(img13_modified)\n",
    "    imshow(img23_modified)\n",
    "    imshow(final)\n",
    "\n",
    "    final = cv2.inpaint(final.astype(np.uint8), mask123.astype(np.uint8), 20, cv2.INPAINT_NS)\n",
    "    imshow(final)\n",
    "    cv2.imwrite('fnal2.jpg', final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('DJI_20231031123737_0028_W.JPG')\n",
    "img2 = cv2.imread('DJI_20231031123813_0040_W.JPG')\n",
    "img3 = cv2.imread('DJI_20231031123834_0047_W.JPG')\n",
    "img4 = cv2.imread('fnal1.jpg')\n",
    "img5 = cv2.imread('fnal2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_img = np.stack((img1, img2, img3, img4, img5))\n",
    "average_img = np.average(stacked_img, axis=0)\n",
    "median_img = np.median(stacked_img, axis=0)\n",
    "print(\"average:\")\n",
    "imshow(average_img)\n",
    "print(\"median:\")\n",
    "imshow(median_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
