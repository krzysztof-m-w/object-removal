{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 - object removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we will try to remove moving objects from the series of images. Basically the task is to recognize regions of the images which are changing between the frames and replace them with static background. The final result should be one image containing only background elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open(img):\n",
    "    return cv2.dilate(cv2.erode(img, np.ones((4,4))), np.ones((4,4)))\n",
    "\n",
    "def close(img, kernel_size):\n",
    "    kernel = np.ones(kernel_size)\n",
    "    return cv2.erode(cv2.dilate(img, kernel), kernel)\n",
    "\n",
    "def dilate(img, kernel_size):\n",
    "    kernel = np.ones(kernel_size)\n",
    "    return cv2.dilate(img, kernel)\n",
    "\n",
    "def erode(img, kernel_size):\n",
    "    kernel = np.ones(kernel_size)\n",
    "    return cv2.erode(img, kernel)\n",
    "\n",
    "def proper_open(img):\n",
    "    to_compare = close(open(close(img)))\n",
    "    stack = np.stack((img, to_compare))\n",
    "    return np.min(stack, axis=0)\n",
    "\n",
    "def proper_close(img):\n",
    "    to_compare = open(close(open(img)))\n",
    "    stack = np.stack((img, to_compare))\n",
    "    return np.max(stack, axis=0)\n",
    "\n",
    "def automedian_filter(img):\n",
    "    to_compare = proper_open(img)\n",
    "    stack = np.stack((img, to_compare))\n",
    "    return np.max(stack, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def imshow(img):\n",
    "    img = img.clip(0, 255).astype(\"uint8\")\n",
    "    if img.ndim == 3:\n",
    "        if img.shape[2] == 4:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGRA2RGBA)\n",
    "        else:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    display(PIL.Image.fromarray(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we base our experiments on is a series of three images of street traffic here the task is obviously to remove the cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('DJI_20231031123737_0028_W.JPG')\n",
    "img2 = cv2.imread('DJI_20231031123813_0040_W.JPG')\n",
    "img3 = cv2.imread('DJI_20231031123834_0047_W.JPG')\n",
    "print(img1.shape)\n",
    "print(img2.shape)\n",
    "print(img3.shape)\n",
    "imshow(img1)\n",
    "imshow(img2)\n",
    "imshow(img3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixel average and median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will try the most basic approach: median and average filtering. The results are effects of conducting those basic operations on corresponding pixels from the three images. \n",
    "\n",
    "We can see that the results of the average filter are rather poor. The cars from all the images are still visible but they are now partially transparent. If the number of the images to process was much higher the influence of the single image would probably be not as significant. But with only 3 the impact of each easily noticeable. \n",
    "\n",
    "The median filter produced better results than the average. For most of the regions the cars were successfully removed however there were some problematic sections. Those sections are the parts of the image were two cars from different frames are located in the same position. Locating those regions on concrete images may be the key to solving the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_img = np.stack((img1, img2, img3))\n",
    "average_img = np.average(stacked_img, axis=0)\n",
    "median_img = np.median(stacked_img, axis=0)\n",
    "print(\"average:\")\n",
    "imshow(average_img)\n",
    "print(\"median:\")\n",
    "imshow(median_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sobel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will try to locate the objects on the images using sobel filter. Based on the places were the edges are detected we will hopefully be able to locate the whole objects. Using that information it will be possible to create masks used to later filtering out the moving objects.\n",
    "\n",
    "We can see that both the cars and surrounding objects: trees, buildings road etc were detected by the algorithm therefore the first task is to filter out only the cars. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First attempt was to remove other objects by using the minimal value among the three sobel pictures. By that way the places were the static objects are located should remain present while cars should be deleted because they will be replaced by the pixels with lower value from the image where there is no edge in that place. Such an image containing only the edges of the trees can be later subtracted from each of the sobel images leaving only the cars on it. \n",
    "\n",
    "The image containing min sobel values indeed seems not to have any cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_grayscale = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "img2_grayscale = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "img3_grayscale = cv2.cvtColor(img3, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "img1_sobel = np.abs(cv2.Sobel(img1_grayscale, cv2.CV_64F, 1, 0, ksize=3))\n",
    "img2_sobel = np.abs(cv2.Sobel(img2_grayscale, cv2.CV_64F, 1, 0, ksize=3))\n",
    "img3_sobel = np.abs(cv2.Sobel(img3_grayscale, cv2.CV_64F, 1, 0, ksize=3))\n",
    "\n",
    "stacked_sobel = np.stack((img1_sobel, img2_sobel, img3_sobel))\n",
    "sobel_min = np.min(stacked_sobel, axis=0)\n",
    "sobel_median = np.median(stacked_sobel, axis=0)\n",
    "\n",
    "imshow(img1_sobel)\n",
    "imshow(img2_sobel)\n",
    "imshow(img3_sobel)\n",
    "imshow(sobel_min)\n",
    "imshow(sobel_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to cover the whole cars filtered sobel edge images needed to be additionally dilated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "sobel_min[sobel_min < 2] = 0\n",
    "reduced = img1_sobel - 5 * sobel_min\n",
    "open_result1 = (open(reduced))\n",
    "binarized1 = (open_result1 > 0).astype(np.uint8) * 255\n",
    "\n",
    "reduced = img2_sobel - 5 * sobel_min\n",
    "open_result2 = (open(reduced))\n",
    "binarized2 = (open_result2 > 0).astype(np.uint8) * 255\n",
    "\n",
    "reduced = img3_sobel - 5 * sobel_min\n",
    "open_result3 = (open(reduced))\n",
    "binarized3 = (open_result3 > 0).astype(np.uint8) * 255\n",
    "\n",
    "for i in range(3):\n",
    "    binarized1 = cv2.dilate(binarized1, np.ones((20,20)))\n",
    "    binarized2 = cv2.dilate(binarized2, np.ones((20,20)))\n",
    "    binarized3 = cv2.dilate(binarized3, np.ones((20,20)))\n",
    "\n",
    "for img, binarized in zip([img1, img2, img3], [binarized1, binarized2, binarized3]):\n",
    "    imshow(img)\n",
    "    imshow(binarized)\n",
    "    stack = np.stack((img, np.repeat(binarized[:,: ,np.newaxis], 3, axis=2)))\n",
    "\n",
    "    imshow(np.average(stack, axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using minimal value and filtering it turned out not to meet the expectations. The cars were discovered but the most crucial parts of the image were marked on all three frames. It makes us unable to properly filter out the object in that regions. It is probably because sobel filter can also produce small values around the edges so during the calculation of the minimal value each image left some artifacts in the places were the cars are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_binarized = np.stack((binarized1, binarized2, binarized3))\n",
    "min_binarized = np.min(stack_binarized, axis=0)\n",
    "imshow(min_binarized)\n",
    "for img, binarized in zip([img1, img2, img3], [min_binarized, min_binarized, min_binarized]):\n",
    "    stack = np.stack((img, np.repeat(binarized[:,: ,np.newaxis], 3, axis=2)))\n",
    "\n",
    "    imshow(np.average(stack, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second approach was to use each of the fames both as a source of information and a mask for filtering out the information. We also used stronger dilation in filtering process. Each edge representation was removed from the other in order for only cars to remain. Filtered edge representations were then processed by the series of erosions and dilations to finally obtain the masks for the cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel1_modified = (img1_sobel > 100).astype(np.uint8) * 255\n",
    "sobel2_modified = (img2_sobel > 500).astype(np.uint8) * 255\n",
    "sobel3_modified = (img3_sobel > 100).astype(np.uint8) * 255\n",
    "\n",
    "\n",
    "kernel = np.ones((3, 3), dtype=np.uint8)\n",
    "\n",
    "sobel1_modified = cv2.dilate(sobel1_modified, kernel)\n",
    "sobel2_modified = cv2.dilate(sobel2_modified, kernel)\n",
    "sobel3_modified = cv2.dilate(sobel3_modified, kernel)\n",
    "\n",
    "imshow(sobel1_modified)\n",
    "imshow(sobel2_modified)\n",
    "imshow(sobel3_modified)\n",
    "\n",
    "img1_sobel_copy = img1_sobel.copy()\n",
    "img1_sobel_copy[sobel2_modified.astype(np.bool_)] = 0\n",
    "img1_sobel_copy[sobel3_modified.astype(np.bool_)] = 0\n",
    "img1_sobel_copy = (img1_sobel_copy > 255).astype(np.uint8) * 255\n",
    "\n",
    "img2_sobel_copy = img2_sobel.copy()\n",
    "img2_sobel_copy[sobel1_modified.astype(np.bool_)] = 0\n",
    "img2_sobel_copy[sobel3_modified.astype(np.bool_)] = 0\n",
    "img2_sobel_copy = (img2_sobel_copy > 230).astype(np.uint8) * 255\n",
    "\n",
    "\n",
    "img3_sobel_copy = img3_sobel.copy()\n",
    "img3_sobel_copy[sobel1_modified.astype(np.bool_)] = 0\n",
    "img3_sobel_copy[sobel2_modified.astype(np.bool_)] = 0\n",
    "img3_sobel_copy = (img3_sobel_copy > 200).astype(np.uint8) * 255\n",
    "\n",
    "imshow(img1_sobel_copy)\n",
    "imshow(img2_sobel_copy)\n",
    "imshow(img3_sobel_copy)\n",
    "\n",
    "if True:\n",
    "    kernel = np.ones((2, 2), dtype=np.uint8)\n",
    "\n",
    "    img1_sobel_copy = cv2.dilate(img1_sobel_copy, kernel)\n",
    "    img2_sobel_copy = cv2.dilate(img2_sobel_copy, kernel)\n",
    "    img3_sobel_copy = cv2.dilate(img3_sobel_copy, kernel)\n",
    "\n",
    "    kernel = np.ones((3, 3), dtype=np.uint8)\n",
    "\n",
    "    img1_sobel_copy = cv2.erode(img1_sobel_copy, kernel)\n",
    "    img2_sobel_copy = cv2.erode(img2_sobel_copy, kernel)\n",
    "    img3_sobel_copy = cv2.erode(img3_sobel_copy, kernel)\n",
    "\n",
    "    if True:\n",
    "        kernel = np.ones((130, 130), dtype=np.uint8)\n",
    "\n",
    "        img1_sobel_copy = cv2.dilate(img1_sobel_copy, kernel)\n",
    "\n",
    "\n",
    "        kernel = np.ones((75, 75), dtype=np.uint8)\n",
    "        img1_sobel_copy = cv2.erode(img1_sobel_copy, kernel)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kernel = np.ones((100, 100), dtype=np.uint8)\n",
    "        img2_sobel_copy = cv2.dilate(img2_sobel_copy, kernel)\n",
    "        kernel = np.ones((45, 45), dtype=np.uint8)\n",
    "        img2_sobel_copy = cv2.erode(img2_sobel_copy, kernel)\n",
    "        kernel = np.ones((7, 7), dtype=np.uint8)\n",
    "        img2_sobel_copy = cv2.erode(img2_sobel_copy, kernel)\n",
    "\n",
    "\n",
    "        kernel = np.ones((20, 20), dtype=np.uint8)\n",
    "        img3_sobel_copy = cv2.dilate(img3_sobel_copy, kernel)\n",
    "        img3_sobel_copy = cv2.dilate(img3_sobel_copy, kernel)\n",
    "        img3_sobel_copy = cv2.dilate(img3_sobel_copy, kernel)\n",
    "\n",
    "        kernel = np.ones((20, 20), dtype=np.uint8)\n",
    "        img3_sobel_copy = cv2.dilate(img3_sobel_copy, kernel)\n",
    "        \n",
    "        \n",
    "        kernel = np.ones((40, 40), dtype=np.uint8)\n",
    "        img3_sobel_copy = cv2.erode(img3_sobel_copy, kernel)\n",
    "\n",
    "        kernel = np.ones((10, 10), dtype=np.uint8)\n",
    "        img3_sobel_copy = cv2.erode(img3_sobel_copy, kernel)\n",
    "\n",
    "\n",
    "for img, binarized in zip([img1, img2, img3], [img1_sobel_copy, img2_sobel_copy, img3_sobel_copy]):\n",
    "    stack = np.stack((img, np.repeat(binarized[:,: ,np.newaxis], 3, axis=2)))\n",
    "\n",
    "    imshow(np.average(stack, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time the final result is much better. Most of the places were properly marked only on the images with the cars in those places. Some of noise and other objects were marked as well but no such discoveries overlap on all three images. The problem is only one small region which contains cars in some of its part in all three regions. The region was marked on all three frames therefore filtering for it still can not be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_min = np.stack((img1_sobel_copy, img2_sobel_copy, img3_sobel_copy))\n",
    "mask_min = np.min(mask_min, axis=0)\n",
    "\n",
    "for img, binarized in zip([img1, img2, img3], [mask_min, mask_min, mask_min]):\n",
    "    stack = np.stack((img, np.repeat(binarized[:,: ,np.newaxis], 3, axis=2)))\n",
    "\n",
    "    imshow(np.average(stack, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on obtained masks we construct the new image. Regions that are not covered by any mask will still be obtained using median filter. Those covered by the one mask will use the average of the two remaining images. Covered by two masks will use the one uncovered region. The one problematic region will be filled using inpaint function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_modified = img1.copy()\n",
    "img2_modified = img2.copy()\n",
    "img3_modified = img3.copy()\n",
    "\n",
    "img12_modified = np.stack((img1, img2))\n",
    "img13_modified = np.stack((img1, img3))\n",
    "img23_modified = np.stack((img2, img3))\n",
    "img12_modified = np.average(img12_modified, axis=0)\n",
    "img13_modified = np.average(img13_modified, axis=0)\n",
    "img23_modified = np.average(img23_modified, axis=0)\n",
    "\n",
    "img123_modified = np.stack((img1, img2, img3))\n",
    "img123_modified = np.median(img123_modified, axis=0)\n",
    "\n",
    "mask1 = img1_sobel_copy.astype(np.bool_)\n",
    "mask2 = img2_sobel_copy.astype(np.bool_)\n",
    "mask3 = img3_sobel_copy.astype(np.bool_)\n",
    "\n",
    "mask12 = mask1 & mask2\n",
    "mask13 = mask1 & mask3\n",
    "mask23 = mask2 & mask3\n",
    " \n",
    "mask123 = mask12 & mask3\n",
    "\n",
    "img1_modified[mask1 | ~mask2 | ~mask3] = 0\n",
    "img2_modified[mask2 | ~mask1 | ~mask3] = 0\n",
    "img3_modified[mask3 | ~mask1 | ~mask2] = 0\n",
    "img12_modified[mask1 | mask2 | ~mask3] = 0\n",
    "img13_modified[mask1 | ~mask2 | mask3] = 0\n",
    "img23_modified[~mask1 | mask2 | mask3] = 0\n",
    "\n",
    "img123_modified[mask1 | mask2 | mask3] = 0\n",
    "\n",
    "final = np.stack((img1_modified, img2_modified, img3_modified, img12_modified, img13_modified, img23_modified, img123_modified))\n",
    "final = np.sum(final, axis=0)\n",
    "imshow(img12_modified)\n",
    "imshow(img13_modified)\n",
    "imshow(img23_modified)\n",
    "imshow(final)\n",
    "\n",
    "final = cv2.inpaint(final.astype(np.uint8), mask123.astype(np.uint8), 20, cv2.INPAINT_NS)\n",
    "imshow(final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
